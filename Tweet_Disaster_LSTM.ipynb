{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Disaster LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMO/ww6xnV3yQ2ZYUjYoCXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/terkoizmy/TweetDisaster/blob/main/Tweet_Disaster_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rei_qKqzbaNr"
      },
      "source": [
        "# Prepare library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqtKSg21I4K_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e737bed5-3b86-49ad-c56f-42ad58b203d7"
      },
      "source": [
        "# download text hamer if you dont have it in your device\n",
        "!pip install text_hammer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting text_hammer\n",
            "  Downloading https://files.pythonhosted.org/packages/84/3a/955cead96434a981761e4dbe5ca24241df8595f9459875ea1be7bf6eece7/text_hammer-0.1.5-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from text_hammer) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from text_hammer) (1.1.5)\n",
            "Collecting beautifulsoup4==4.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/25/ff030e2437265616a1e9b25ccc864e0371a0bc3adb7c5a404fd661c6f4f6/beautifulsoup4-4.9.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from text_hammer) (2.2.4)\n",
            "Requirement already satisfied: TextBlob in /usr/local/lib/python3.7/dist-packages (from text_hammer) (0.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->text_hammer) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->text_hammer) (2018.9)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (56.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->text_hammer) (0.4.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from TextBlob->text_hammer) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->text_hammer) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->text_hammer) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->text_hammer) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->text_hammer) (3.7.4.3)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, text-hammer\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.9.1 soupsieve-2.2.1 text-hammer-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy-7DYlR6u5R",
        "outputId": "6c658368-a18e-4264-e3f0-0be1107d609a"
      },
      "source": [
        "# Import library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import text_hammer as th\n",
        "import re\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.layers import Dense, LSTM, Dropout, Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "%matplotlib inline\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3tJa2tGc73i"
      },
      "source": [
        "## Download Glove for embeding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY7EZtK-WP0D",
        "outputId": "901acebe-72b0-4c8b-b6a8-25e2648a6ec6"
      },
      "source": [
        "# Download Glove file\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# Unzip file\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-26 00:49:22--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-05-26 00:49:22--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-05-26 00:49:23--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 40s  \n",
            "\n",
            "2021-05-26 00:52:03 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8VNfyuBbsEF"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NppJPn7SLc0H"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Z3LS6Se-JNhj",
        "outputId": "1f72ab24-d9b2-4da4-e0f9-ab7368650231"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMovVZL_MRfz",
        "outputId": "10ab8f50-fca5-41f2-8ffd-ccb2e11a74dc"
      },
      "source": [
        "df_train.text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Our Deeds are the Reason of this #earthquake M...\n",
              "1                  Forest fire near La Ronge Sask. Canada\n",
              "2       All residents asked to 'shelter in place' are ...\n",
              "3       13,000 people receive #wildfires evacuation or...\n",
              "4       Just got sent this photo from Ruby #Alaska as ...\n",
              "                              ...                        \n",
              "7608    Two giant cranes holding a bridge collapse int...\n",
              "7609    @aria_ahrary @TheTawniest The out of control w...\n",
              "7610    M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
              "7611    Police investigating after an e-bike collided ...\n",
              "7612    The Latest: More Homes Razed by Northern Calif...\n",
              "Name: text, Length: 7613, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfgIKdu4b0Cl"
      },
      "source": [
        "## Text processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bR0bez5PnDr"
      },
      "source": [
        "# Text Processing\n",
        "def preprocess_text(texts):\n",
        "  corpus = []\n",
        "  for text in texts:\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+|http?://\\S+','',text)\n",
        "    text = re.sub(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # removal of emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           \"]+\",' ',text)\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    wl = WordNetLemmatizer()\n",
        "    all_stopwords = stopwords.words('english')\n",
        "    text = [wl.lemmatize(word) for word in text if not word in set(all_stopwords)]\n",
        "    text = [i for i in text if len(i)>2]\n",
        "    text = ' '.join(text)\n",
        "    corpus.append(text)\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76UganYJNg86"
      },
      "source": [
        "# Use text Processing\n",
        "df_train['processed_text'] = preprocess_text(df_train['text'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPh7ak5WZmfm",
        "outputId": "3ac6f08e-30fb-49ef-ba2c-e482ef54a623"
      },
      "source": [
        "print(df_train['processed_text'][1:5])\n",
        "print(df_train['text'][1:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1                   forest fire near ronge sask canada\n",
            "2    resident asked shelter place notified officer ...\n",
            "3    people receive wildfire evacuation order calif...\n",
            "4    got sent photo ruby alaska smoke wildfire pour...\n",
            "Name: processed_text, dtype: object\n",
            "1               Forest fire near La Ronge Sask. Canada\n",
            "2    All residents asked to 'shelter in place' are ...\n",
            "3    13,000 people receive #wildfires evacuation or...\n",
            "4    Just got sent this photo from Ruby #Alaska as ...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzuUqub6b7xC"
      },
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnoU662iP6zJ"
      },
      "source": [
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_train['processed_text'], df_train['target'], test_size = 0.20)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aYT45uIeH0g",
        "outputId": "9af9a85c-7761-4a2f-bf85-5e209bf5cdd0"
      },
      "source": [
        "print(X_train[3])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "people receive wildfire evacuation order california\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI_5uxPocLVy"
      },
      "source": [
        "## Declare the vocabulary size for word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfENPiYKZaUp"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "top_words = 1000\n",
        "t = Tokenizer(num_words=top_words) # num_words -> Vocablury size\n",
        "t.fit_on_texts(X_train.tolist())\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7gAUFNZcVUM"
      },
      "source": [
        "## Generate the word index for train and val data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydh7zB36dA3Y"
      },
      "source": [
        "X_train = t.texts_to_sequences(X_train.tolist())\n",
        "X_val = t.texts_to_sequences(X_val.tolist())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpVTcQ81d-oh",
        "outputId": "b860825a-544d-41f2-d139-0512207209d3"
      },
      "source": [
        "print(X_train[3])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[56, 165, 518]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBEIbc02ccWJ"
      },
      "source": [
        "## Pading the sequence of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXySj_1odH2P"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "max_review_length = 50\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_review_length, padding='post')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml2l4XrDeGJn",
        "outputId": "e0cae433-a749-43cb-ad4a-59e0f78f3ae2"
      },
      "source": [
        "print(X_train[3])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 56 165 518   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaeU_NmedR3w"
      },
      "source": [
        "# Embeding Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJRupkUydm7a"
      },
      "source": [
        "## Convert glove to Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b0ZnbuqMSbi",
        "outputId": "237b8df2-dcfe-4b7f-f9ff-a6c0fdd99a3c"
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec(\"glove.6B.50d.txt\", \"glove.6B.50d.txt.word2vec\") \n",
        "# param 1: Glove file, param 2: Glove fileName for word2vec file "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzRX8WrmeDSZ"
      },
      "source": [
        "## pretrained model glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkoEL48MXRip"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B.50d.txt.word2vec\", binary=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAZzyDI4YUfK",
        "outputId": "8addc6de-403b-4a6f-8b46-7d1c2bb544f5"
      },
      "source": [
        "#Embedding length based on selected model - we are using 50d here.\n",
        "embedding_vector_length = 50\n",
        "\n",
        "#Initialize embedding matrix\n",
        "embedding_matrix = np.zeros((top_words + 1, embedding_vector_length))\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1001, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8frhuMga7xk"
      },
      "source": [
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > (top_words+1):\n",
        "        break\n",
        "    try:\n",
        "        embedding_vector = glove_model[word] #Reading word's embedding from Glove model for a given word\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp6oSdgUbURu",
        "outputId": "267f13d7-ae8b-4231-c102-741b9c6a261e"
      },
      "source": [
        "embedding_matrix[3]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.68079990e-01,  2.08340004e-01, -2.23189995e-01,  4.62829992e-02,\n",
              "        2.00979993e-01,  2.75150001e-01, -7.71269977e-01, -7.68040001e-01,\n",
              "       -3.48610014e-01,  5.06200016e-01, -2.44010001e-01,  7.17750013e-01,\n",
              "       -3.33480000e-01,  3.75539988e-01,  4.47560012e-01,  3.66979986e-01,\n",
              "        4.35330003e-01,  4.75699991e-01, -5.61130010e-02, -9.35310006e-01,\n",
              "       -2.75909990e-01,  3.16100001e-01,  2.21159995e-01,  3.63040000e-01,\n",
              "        1.07570000e-01, -1.76380002e+00, -1.26240003e+00,  3.02839994e-01,\n",
              "        5.62860012e-01, -1.02139997e+00,  3.23530006e+00,  4.84829992e-01,\n",
              "        2.79530007e-02,  3.60819995e-02, -7.85539970e-02,  1.87610000e-01,\n",
              "       -5.25730014e-01,  3.72000001e-02,  2.75790006e-01, -7.73599967e-02,\n",
              "       -2.79549986e-01,  7.97519982e-01,  1.60279998e-03,  4.54789996e-01,\n",
              "        8.83819997e-01,  4.38930005e-01, -1.92629993e-01, -6.72360003e-01,\n",
              "       -3.97089988e-01,  2.51830012e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-a5fSje13h"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XsvLmSbbpPB"
      },
      "source": [
        "#Initialize model\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoqLhXDdfCrF"
      },
      "source": [
        "## input embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6qhtBbMbueM"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding( top_words+ 1, #Vocablury size\n",
        "                                    embedding_vector_length, #Embedding size\n",
        "                                    weights=[embedding_matrix], #Embeddings taken from pre-trained model\n",
        "                                    trainable=False, #As embeddings are already available, we will not train this layer. It will act as lookup layer.\n",
        "                                    input_length=max_review_length) #Number of words in each review\n",
        "         )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUHjkfJ2fLDw"
      },
      "source": [
        "## imput LSTM layer and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL2mazVJcG5w"
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(256)) #RNN State - size of cell state and hidden state\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ParrtO-jb2J5",
        "outputId": "e0386678-c283-41d0-8425-7f995837b46f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            50050     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               314368    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 364,675\n",
            "Trainable params: 314,625\n",
            "Non-trainable params: 50,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIkbsKEofT7o"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNY15RSFd1nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e96a8f0-043e-4bad-887e-cc905f91ce1a"
      },
      "source": [
        "model.fit(X_train,y_train,\n",
        "          epochs=10,\n",
        "          batch_size=32,          \n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "191/191 [==============================] - 36s 175ms/step - loss: 0.6184 - accuracy: 0.6658 - val_loss: 0.5406 - val_accuracy: 0.7584\n",
            "Epoch 2/10\n",
            "191/191 [==============================] - 33s 171ms/step - loss: 0.5176 - accuracy: 0.7603 - val_loss: 0.5389 - val_accuracy: 0.7774\n",
            "Epoch 3/10\n",
            "191/191 [==============================] - 33s 174ms/step - loss: 0.5111 - accuracy: 0.7635 - val_loss: 0.4977 - val_accuracy: 0.7768\n",
            "Epoch 4/10\n",
            "191/191 [==============================] - 33s 173ms/step - loss: 0.4915 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7663\n",
            "Epoch 5/10\n",
            "191/191 [==============================] - 33s 172ms/step - loss: 0.4799 - accuracy: 0.7742 - val_loss: 0.5150 - val_accuracy: 0.7722\n",
            "Epoch 6/10\n",
            "191/191 [==============================] - 32s 170ms/step - loss: 0.4803 - accuracy: 0.7806 - val_loss: 0.4768 - val_accuracy: 0.7814\n",
            "Epoch 7/10\n",
            "191/191 [==============================] - 33s 171ms/step - loss: 0.4671 - accuracy: 0.7836 - val_loss: 0.4849 - val_accuracy: 0.7866\n",
            "Epoch 8/10\n",
            "191/191 [==============================] - 33s 172ms/step - loss: 0.4587 - accuracy: 0.7918 - val_loss: 0.4643 - val_accuracy: 0.7919\n",
            "Epoch 9/10\n",
            "191/191 [==============================] - 32s 170ms/step - loss: 0.4490 - accuracy: 0.8003 - val_loss: 0.4805 - val_accuracy: 0.7807\n",
            "Epoch 10/10\n",
            "191/191 [==============================] - 33s 171ms/step - loss: 0.4518 - accuracy: 0.7952 - val_loss: 0.4732 - val_accuracy: 0.7932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff42d5fc390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRCnW6z8fdTi"
      },
      "source": [
        "val_pred=model.predict(X_val)\n",
        "val_pred = np.where(val_pred > 0.5,1,0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Bs0zFCgZGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ecb12a-ae99-4d89-9d29-4740f830caa2"
      },
      "source": [
        "val_pred"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJLXozE-ggLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3b0382-8af3-4ba4-e6fc-e0786772a21e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val, val_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       872\n",
            "           1       0.82      0.66      0.73       651\n",
            "\n",
            "    accuracy                           0.79      1523\n",
            "   macro avg       0.80      0.78      0.78      1523\n",
            "weighted avg       0.80      0.79      0.79      1523\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKyY0T9Eddin"
      },
      "source": [
        "# Store the output of lstm\n",
        "x = model.get_layer('lstm').output\n",
        "model2 = tf.keras.Model(model.input, x)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t54eYqmwd6EL"
      },
      "source": [
        "# Full train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfzZ70ZXeMBb"
      },
      "source": [
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzllpqpqeQQj"
      },
      "source": [
        "df_test['processed_text'] = preprocess_text(df_test['text'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD7-mKtKd5F7"
      },
      "source": [
        "### Declare the vocabulary size for word embedding\n",
        "t = Tokenizer(num_words=top_words) # num_words -> Vocablury size\n",
        "t.fit_on_texts(df_train['processed_text'].tolist())\n",
        "train_seq  = t.texts_to_sequences(df_train['processed_text'].tolist())\n",
        "test_seq  = t.texts_to_sequences(df_test['processed_text'].tolist())\n",
        "\n",
        "train_seq = sequence.pad_sequences(train_seq,maxlen=max_review_length,padding='post')\n",
        "test_seq = sequence.pad_sequences(test_seq, maxlen=max_review_length, padding='post')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1AYj444Hwc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4543fd7-9fef-410c-8157-3d9ded37b4e3"
      },
      "source": [
        "train_seq"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[446, 156,  64, ...,   0,   0,   0],\n",
              "       [101,   1, 140, ...,   0,   0,   0],\n",
              "       [447, 302, 157, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [607, 380,   0, ...,   0,   0,   0],\n",
              "       [ 18, 963, 258, ...,   0,   0,   0],\n",
              "       [125,  17, 404, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u-RYdkdeEbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4b144f-c0ed-4411-9fa6-10bfc56416a9"
      },
      "source": [
        "model.fit(train_seq,df_train['target'],\n",
        "          epochs=25,\n",
        "          batch_size=32)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.6657 - accuracy: 0.5868\n",
            "Epoch 2/25\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.6346 - accuracy: 0.6473\n",
            "Epoch 3/25\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.6030 - accuracy: 0.6774\n",
            "Epoch 4/25\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.5642 - accuracy: 0.7148\n",
            "Epoch 5/25\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.5384 - accuracy: 0.7400\n",
            "Epoch 6/25\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.5236 - accuracy: 0.7466\n",
            "Epoch 7/25\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.4988 - accuracy: 0.7622\n",
            "Epoch 8/25\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.4829 - accuracy: 0.7766\n",
            "Epoch 9/25\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.4658 - accuracy: 0.7890\n",
            "Epoch 10/25\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.4460 - accuracy: 0.7969\n",
            "Epoch 11/25\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.4349 - accuracy: 0.8070\n",
            "Epoch 12/25\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.4259 - accuracy: 0.8126\n",
            "Epoch 13/25\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.3985 - accuracy: 0.8296\n",
            "Epoch 14/25\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3898 - accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "238/238 [==============================] - 42s 177ms/step - loss: 0.3757 - accuracy: 0.8388\n",
            "Epoch 16/25\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.3608 - accuracy: 0.8489\n",
            "Epoch 17/25\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.3578 - accuracy: 0.8505\n",
            "Epoch 18/25\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.3531 - accuracy: 0.8510\n",
            "Epoch 19/25\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.3141 - accuracy: 0.8698\n",
            "Epoch 20/25\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3113 - accuracy: 0.8748\n",
            "Epoch 21/25\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.2967 - accuracy: 0.8802\n",
            "Epoch 22/25\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.2806 - accuracy: 0.8893\n",
            "Epoch 23/25\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.2710 - accuracy: 0.8914\n",
            "Epoch 24/25\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.2711 - accuracy: 0.8947\n",
            "Epoch 25/25\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.2573 - accuracy: 0.9017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff4296db490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7OcvGjZYJBx"
      },
      "source": [
        "test_pred=model.predict(test_seq)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rboe4iV4YMTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b0e9ce-1492-4ef0-ce14-297f9e849c42"
      },
      "source": [
        "test_pred"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7546619 ],\n",
              "       [0.71892893],\n",
              "       [0.04489338],\n",
              "       ...,\n",
              "       [0.22225174],\n",
              "       [0.8334807 ],\n",
              "       [0.10308999]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcHztabzYiZz"
      },
      "source": [
        "df_test['target']=np.where(test_pred > 0.5,1,0)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlwFp3wkY7VZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b44b521-eb75-42e1-91fb-145e6d80b737"
      },
      "source": [
        "df_test['target']"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       0\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "3258    1\n",
              "3259    1\n",
              "3260    0\n",
              "3261    1\n",
              "3262    0\n",
              "Name: target, Length: 3263, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDGdPgCMZkXJ"
      },
      "source": [
        "submit = pd.DataFrame()\n",
        "submit['id'] = df_test['id']\n",
        "submit['target'] = df_test['target']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohO0ifaRZoJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a0ce1158-63c1-4b6b-ad55-825d1ea47802"
      },
      "source": [
        "submit"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       1\n",
              "1         2       1\n",
              "2         3       0\n",
              "3         9       1\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       0\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAJCFB1TQP_m"
      },
      "source": [
        "# save to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBssVxLiYC0y"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIh0oTE6acm9"
      },
      "source": [
        "submit.to_csv('/content/gdrive/MyDrive/Submission/submit_LSTM.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}